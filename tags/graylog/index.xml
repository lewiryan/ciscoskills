<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>graylog on Cisco Skills</title>
    <link>http://archive.ciscoskills.net.s3-website-us-west-2.amazonaws.com/tags/graylog/</link>
    <description>Recent content in graylog on Cisco Skills</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 21 Jun 2019 18:05:55 +0000</lastBuildDate><atom:link href="http://archive.ciscoskills.net.s3-website-us-west-2.amazonaws.com/tags/graylog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Graylog with AWS Elasticsearch</title>
      <link>http://archive.ciscoskills.net.s3-website-us-west-2.amazonaws.com/2019/06/graylog-with-aws-elasticsearch/</link>
      <pubDate>Fri, 21 Jun 2019 18:05:55 +0000</pubDate>
      
      <guid>http://archive.ciscoskills.net.s3-website-us-west-2.amazonaws.com/2019/06/graylog-with-aws-elasticsearch/</guid>
      <description>
        
          &lt;p&gt;Graylog has been through some changes last time I talked about them, hitting version 3.0 in February is awesome and one of things that make Graylog run well is Elasticsearch backend. Although Elasticsearch is not too hard to setup it usually runs better on bare metal, so there is cost of that as well as maintenance of the cluster is important, updates and upgrades. Depending your team experience you may not have time to learn it or run it the way it should be. That last thing you want is your logging setup to go down because of poor maintenance. So in this post we will walk though setting up a Graylog Server and using AWS Elasticsearch service for our backend. Without having a quick Elasticsearch cluster Graylog experience suffers, so let&#39;s get started.&lt;/p&gt;
&lt;p&gt;The first thing and easiest thing is to spin up an Elasticsearch cluster within AWS. Depending on your use case you may only want a development deployment (single-node) or you can do a 3 or 2 node cluster within different availability zones within AWS, so its up to you and your wallet ;) of how big or small you want this Elasticsearch resource.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Additional security protections are recommended if this going to be used for production, like one example is don&#39;t open Elasticsearch to the internet without ACLs in place!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If you want more information about Elasticsearch service that AWS provides go ahead and read AWS Developer Guide - &lt;a href=&#34;https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/what-is-amazon-elasticsearch-service.html&#34;&gt;Amazon Elasticsearch Service.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Once your cluster is up and running, keep note of the Endpoint URL you will need that for Graylog. In this example I&#39;m using Centos 7 for the Graylog Server and depending on the operating system you are using for the Graylog server follow the instructions on &lt;a href=&#34;http://docs.graylog.org/en/latest/pages/installation/operating_system_packages.html&#34;&gt;Graylog&#39;s Read the Docs&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;No need for me to repeat installation steps, in this example I&#39;m using Centos 7 and followed the &lt;a href=&#34;http://docs.graylog.org/en/latest/pages/installation/os/centos.html&#34;&gt;documentation&lt;/a&gt;. Since we have an Elasticsearch cluster provided by AWS you don&#39;t need to anything related to Elasticsearch when installing Graylog, so skip it. Once you have Graylog installed go ahead and start it up to make sure you get the webpage and can login. This just verifies you have a working Graylog server ready to go. You might see some errors related to indexing but that is expected, we have not told Graylog about our AWS Elasticsearch resource.
&lt;img src=&#34;http://archive.ciscoskills.net.s3-website-us-west-2.amazonaws.com/images/2019/04/graylog-es-aws.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Login into your Graylog server and with your favorite text editor open the Graylog server configuration file /etc/graylog/server/server.conf We are looking to modify the Elasticsearch hosts by default its local host to the Endpoint URL that is in your AWS Elasticsearch resource.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;# List of Elasticsearch hosts Graylog should connect to.
&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;# Need to be specified as a comma-separated list of valid URIs for the http ports of your elasticsearch nodes.
&lt;span class=&#34;ln&#34;&gt;3&lt;/span&gt;# If one or more of your elasticsearch hosts require authentication, include the credentials in each node URI that
&lt;span class=&#34;ln&#34;&gt;4&lt;/span&gt;# requires authentication.
&lt;span class=&#34;ln&#34;&gt;5&lt;/span&gt;#
&lt;span class=&#34;ln&#34;&gt;6&lt;/span&gt;# Default: http://127.0.0.1:9200
&lt;span class=&#34;ln&#34;&gt;7&lt;/span&gt;elasticsearch\_hosts = https://search-24726754557.us-west-2.es.amazonaws.com/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Restart the Graylog server service&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;systemctl restart graylog-server
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You now have Graylog server backed by an AWS Elasticsearch Cluster, log away :)
&lt;img src=&#34;http://archive.ciscoskills.net.s3-website-us-west-2.amazonaws.com/images/2019/04/graylog-es-aws-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;AWS makes deploying Graylog even easier if you don&#39;t want to have your own Elasticsearch cluster. Although you can&#39;t stop the AWS ES Cluster you can snapshot the data to an S3 bucket and import it back into a new ES cluster and connect Graylog back to it. This makes it so you don&#39;t have this running 24x7, maybe useful for temporary debugging logs or run it 24x7. Well that&#39;s all I got for a Friday, and its the first day of summer &amp;quot;officially&amp;quot; so time enjoy it! I do hope this information is helpful but also enjoy your summer! 8-)&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>FMC Syslog with Graylog Extractor</title>
      <link>http://archive.ciscoskills.net.s3-website-us-west-2.amazonaws.com/2019/02/fmc-syslog-with-graylog-extractor/</link>
      <pubDate>Tue, 05 Feb 2019 17:15:07 +0000</pubDate>
      
      <guid>http://archive.ciscoskills.net.s3-website-us-west-2.amazonaws.com/2019/02/fmc-syslog-with-graylog-extractor/</guid>
      <description>
        
          &lt;p&gt;Let&#39;s continue to talk about the Cisco Firepower Management Center, in this post we are going to look at sending connection events over to syslog. In this example I&#39;m using &lt;a href=&#34;https://www.graylog.org/&#34;&gt;Graylog&lt;/a&gt; which is an open source logging platform and  although any syslog server would work, one of the problems with syslogs is there is little uniformity when you have different systems sending these logs. One of the things that Graylog can to do is extract the raw message and put each part of message into a separate searchable field. We&#39;ll configure the FMC to send syslogs and then configure an extractor on Graylog.&lt;/p&gt;
&lt;p&gt;So we have the FMC and Graylog in our environment setup. We&#39;ll want to first configure the FMC and add a syslog server. We can do this two ways, one way is we can go to into Policy tab-&amp;gt; Actions-&amp;gt;Alerts-&amp;gt;Create Alert (Down Arrow)-&amp;gt;Create Syslog Alert.
&lt;img src=&#34;http://archive.ciscoskills.net.s3-website-us-west-2.amazonaws.com/images/2018/08/fmc-syslog-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;You could also go into an access control policy and select log (&lt;img src=&#34;http://archive.ciscoskills.net.s3-website-us-west-2.amazonaws.com/images/2018/08/fmc-log-symbol.jpg&#34; alt=&#34;::inline&#34;&gt;) icon either in the default action or on a rule you would like to log. Another window will show and select the green plus icon and add the syslog server that way.
&lt;img src=&#34;http://archive.ciscoskills.net.s3-website-us-west-2.amazonaws.com/images/2018/08/fmc-syslog-2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once that is out-of-the-way we can now go into Graylog and configure an extractor on the syslog input. This is located under System-&amp;gt;Inputs then under the syslog input select manage extractor. On the actions tab select import extractor and paste this JSON followed by selecting the Add extractors to input at the bottom of the page.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;extractors&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;title&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;FMC – Default Fields&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;extractor_type&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;grok&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;converters&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[],&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;order&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;cursor_strategy&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;copy&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;source_field&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;message&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;target_field&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;extractor_config&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;#34;grok_pattern&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;%{WORD:field}: Protocol: %{WORD:protocol}, SrcIP: %{IP:Source_IP}, OriginalClientIP: ::, DstIP: %{IP:Destination_IP}, SrcPort: %{INT:src_port}, DstPort: %{INT:dest_port}, TCPFlags: %{WORD:flags}, IngressZone: %{HOSTNAME:ingress_zone}, EgressZone: %{HOSTNAME:egress_zone}, DE: %{DATA:detect_engine}, Policy: %{DATA:policy}, ConnectType: %{WORD:connectType}, AccessControlRuleName: %{DATA:ACLRuleName}, AccessControlRuleAction: %{DATA:ACLRuleAction},&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;13&lt;/span&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;#34;named_captures_only&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;14&lt;/span&gt;      &lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;15&lt;/span&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;condition_type&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;regex&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;16&lt;/span&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;condition_value&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;( SFIMS:)&amp;#34;&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;17&lt;/span&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;18&lt;/span&gt;  &lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;19&lt;/span&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;version&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;2.4.6&amp;#34;&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;I have noticed that it might take some time for Graylog to extract the messages as well as it seems there is a delay in the Cisco FMC when sending syslogs but If everything is configured correctly you should start to see logs coming into Graylog. I normally use this for researching firewall rules as its easier to run a search in Graylog then it is on the FMC. Here is what the raw message looks like:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;_DMZ-FW02 SFIMS: Protocol: TCP, SrcIP: 172.25.45.55, OriginalClientIP: ::, DstIP: 172.25.30.82, SrcPort: 58996, DstPort: 1433, TCPFlags: 0x0, IngressZone: LOC-DMZ, EgressZone: LOC-INSIDE, DE: Primary Detection Engine (d4d9f400-c6d2-4065-9f90-da61a963b980), Policy: Acme DMZ ACP, ConnectType: Start, AccessControlRuleName: WEBSRVS-&amp;gt;SQLSRVS-&amp;gt;TCP1443, AccessControlRuleAction: Allow, Prefilter Policy: Default Prefilter Policy, UserName: No Authentication Required, InitiatorPackets: 2, ResponderPackets: 1, InitiatorBytes: 120, ResponderBytes: 66, NAPPolicy: Acme DMZ NAP, DNSResponseType: No Error, Sinkhole: Unknown, URLCategory: Unknown, URLReputation: Risk unknown_
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here is what Graylog would be able to extract from that message with our extractor:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;ACLRuleAction
&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;Allow
&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;ACLRuleName
&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;WEBSRVS-&amp;gt;SQLSRVS-&amp;gt;TCP1443
&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;Destination_IP
&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;172.25.30.82
&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;Source_IP
&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;172.25.45.55
&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;connectType
&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;Start
&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;dest_port
&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;1433
&lt;span class=&#34;ln&#34;&gt;13&lt;/span&gt;detect_engine
&lt;span class=&#34;ln&#34;&gt;14&lt;/span&gt;Primary Detection Engine (d4d9f400-c6d2-4065-9f90-da61a963b980)
&lt;span class=&#34;ln&#34;&gt;15&lt;/span&gt;egress_zone
&lt;span class=&#34;ln&#34;&gt;16&lt;/span&gt;LOC-INSIDE
&lt;span class=&#34;ln&#34;&gt;17&lt;/span&gt;field
&lt;span class=&#34;ln&#34;&gt;18&lt;/span&gt;SFIMS
&lt;span class=&#34;ln&#34;&gt;19&lt;/span&gt;flags
&lt;span class=&#34;ln&#34;&gt;20&lt;/span&gt;0x0
&lt;span class=&#34;ln&#34;&gt;21&lt;/span&gt;ingress_zone
&lt;span class=&#34;ln&#34;&gt;22&lt;/span&gt;LOC-DMZ
&lt;span class=&#34;ln&#34;&gt;23&lt;/span&gt;policy
&lt;span class=&#34;ln&#34;&gt;24&lt;/span&gt;Acme DMZ ACP
&lt;span class=&#34;ln&#34;&gt;25&lt;/span&gt;protocol
&lt;span class=&#34;ln&#34;&gt;26&lt;/span&gt;TCP
&lt;span class=&#34;ln&#34;&gt;27&lt;/span&gt;src_port
&lt;span class=&#34;ln&#34;&gt;28&lt;/span&gt;58996
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With this grok pattern that we created with Graylog we are able to search these fields like Source IP and Destination IP and even the ACLRule name.
&lt;img src=&#34;http://archive.ciscoskills.net.s3-website-us-west-2.amazonaws.com/images/2018/08/gl-aclrulename.png&#34; alt=&#34;gl-aclrulename&#34;&gt;&lt;/p&gt;
&lt;p&gt;This makes it much easier to search these results as well as put this type of data into dashboards or reports. Like always I hope this information is helpful you can find more information about Graylog by hitting their site and try it out for yourself. :)&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Installing Graylog on Centos 7</title>
      <link>http://archive.ciscoskills.net.s3-website-us-west-2.amazonaws.com/2016/01/installing-graylog-on-centos-7/</link>
      <pubDate>Fri, 01 Jan 2016 07:01:00 +0000</pubDate>
      
      <guid>http://archive.ciscoskills.net.s3-website-us-west-2.amazonaws.com/2016/01/installing-graylog-on-centos-7/</guid>
      <description>
        
          &lt;p&gt;&lt;img src=&#34;https://systemstechblog.files.wordpress.com/2015/12/graylog-logo.png?w=150&#34; alt=&#34;Graylog-logo&#34;&gt;Let&#39;s start out 2016 with setting up a logging system called Graylog. If you have not used Graylog before then I encourage you to check it out. This is an open source log management system and is pretty flexible as it can capture, index and analyze almost anything. Once up and running this system can be scaled out for an enterprise wide log management system. High availability, clustered, and replicated is what Graylog thrives on. In this demo I am going to have two systems. One is the Graylog server, web server and will also have a Mongo database. The other system will be an Elasticsearch node which is what will have the actual data stored in and indexed. For bigger “production” ready setups you just scale this out to separate systems. Documentation is key here and Graylog has done an excellent job of it so here it is in case you need it: &lt;a href=&#34;http://docs.graylog.org/en/1.3/index.html&#34;&gt;http://docs.graylog.org/en/1.3/index.html&lt;/a&gt; I’m already assuming that you have CentOS 7 minimal installed if not you can pick up the latest CentOS at &lt;a href=&#34;http://www.centos.org/&#34;&gt;http://www.centos.org/&lt;/a&gt; .The Centos systems also need a connection to the internet, and have just the root account. I&#39;m using two systems for this tutorial so keep that in mind, here are the names of each system and what their role is:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SERVER NAME&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SERVER ROLE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Graylog1 (192.168.148.130)&lt;/p&gt;
&lt;p&gt;Graylog/Web/Mongo Server&lt;/p&gt;
&lt;p&gt;Graylog2 (192.168.148.132)&lt;/p&gt;
&lt;p&gt;Elasticsearch Node&lt;/p&gt;
&lt;p&gt;First let&#39;s login as the root account and update both systems and accept any updates before we do anything else. [code]yum update[/code] Install by favorite text editor for Linux called nano and wget on both systems. (We need to make modifications to some configuration files) [code]yum install nano wget[/code] Also we need Java on both systems so let&#39;s install that. [code]yum install java-1.8.0-openjdk[/code] Let&#39;s start with server &lt;strong&gt;Graylog2&lt;/strong&gt; which will have the Elasticsearch service installed. This can be pretty big in size depending on the amount of logs you&#39;re pushing into Graylog and the retention period you have. (By default its 20 indices) Also as a note you have the the ability to cluster these Elasticseach nodes which can add additional space and redundancy to Graylog. In this tutorial we are just doing one server and currently Graylog does not support Elasticsearch 2.X so we to need install Elasticsearch 1.7.x. I downloaded the RPM package to root’s home directory on Graylog2. You can either use WinSCP or use wget to download that file. I then ran the following to install Elasticsearch 1.7.x. Remember install the latest 1.7.x version. Reference:&lt;a href=&#34;https://www.elastic.co/downloads/past-releases&#34;&gt;https://www.elastic.co/downloads/past-releases&lt;/a&gt; [code]rpm -Uvh elasticsearch-1.7.4.noarch.rpm[/code] &lt;strong&gt;&lt;em&gt;(Side Conversation):&lt;/em&gt;&lt;/strong&gt; &lt;em&gt;By default the Elasicsearch stores its information in the var/lib/elasticsearch folder. Depending on the size of the Centos server you may want to change the default location, especially if you had Centos auto partition your drive. Usually the /home folder has the most space available and this varies on installations so on your own you can check by running df -h to view partitions. To change the save location for Elasicsearch edit the elasticsearch.yml located at /etc/elasticsearch/. You want to look for path.data and uncommnet it out and put down where you want Elasicsearch to store indexes. (Its easier to do this now then to wait until your partition is full&lt;/em&gt; :) &lt;em&gt;)&lt;/em&gt; Start elastic on bootup: [code]sudo systemctl enable elasticsearch.service[/code] Start the Elasticsearch service: [code]sudo systemctl start elasticsearch.service[/code] Verify Elasticsearch service is started: [code][root@GRAYLOG2 ~]# systemctl status elasticsearch.service â elasticsearch.service - Elasticsearch Loaded: loaded (/usr/lib/systemd/system/elasticsearch.service; enabled; vendor preset: disabled) Active: active (running) since Mon 2015-12-21 21:00:42 MST; 52s ago Docs: &lt;a href=&#34;http://www.elastic.co&#34;&gt;http://www.elastic.co&lt;/a&gt; Main PID: 2835 (java) CGroup: /system.slice/elasticsearch.service ââ2835 /bin/java -Xms256m -Xmx1g -Djava.awt.headless=true -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiating... Dec 21 21:00:42 GRAYLOG2 systemd[1]: Started Elasticsearch. Dec 21 21:00:42 GRAYLOG2 systemd[1]: Starting Elasticsearch...[/code] Additional verification: [code][root@GRAYLOG2 ~]# curl -XGET http://127.0.0.1:9200 { &amp;quot;status&amp;quot; : 200, &amp;quot;name&amp;quot; : &amp;quot;Norrin Radd&amp;quot;, &amp;quot;cluster_name&amp;quot; : &amp;quot;elasticsearch&amp;quot;, &amp;quot;version&amp;quot; : { &amp;quot;number&amp;quot; : &amp;quot;1.7.4&amp;quot;, &amp;quot;build_hash&amp;quot; : &amp;quot;0d3159b9fc8bc8e367c5c40c09c2a57c0032b32e&amp;quot;, &amp;quot;build_timestamp&amp;quot; : &amp;quot;2015-12-15T11:25:18Z&amp;quot;, &amp;quot;build_snapshot&amp;quot; : false, &amp;quot;lucene_version&amp;quot; : &amp;quot;4.10.4&amp;quot; }, &amp;quot;tagline&amp;quot; : &amp;quot;You Know, for Search&amp;quot; } [root@GRAYLOG2 ~]#[/code] Allow a range of ports on the CentOS system for management and Elasticsearch functions. [code]firewall-cmd --permanent --zone=public --add-port=9200-9400/tcp[/code] Reload the firewall: [code]firewall-cmd --reload[/code] Install the browser plugin for Elasticsearch. [code]cd /usr/share/elasticsearch/ bin/plugin -install mobz/elasticsearch-head[/code] Point your browser to the Elasticsearch node &lt;a href=&#34;http://ip-address:9200&#34;&gt;http://ip-address:9200&lt;/a&gt; you should see the same information as you did when you issued the curl command. You can view the plugin that was install by going to &lt;a href=&#34;http://ip-address:9200/_plugin/head/&#34;&gt;http://ip-address:9200/_plugin/head/&lt;/a&gt; (This is very helpful to see the elastic cluster) We now need to modify some configuration on the Elasticsearch node. We will be editing /etc/elasticsearch/elasticsearch.yml [code]nano /etc/elasticsearch/elasticsearch.yml[/code] Edit the following: [code highlight=&amp;quot;6,13&amp;quot;]################################### Cluster ################################### # Cluster name identifies your cluster for auto-discovery. If you&#39;re running # multiple clusters on the same network, make sure you&#39;re using unique names. # cluster.name: graylog #################################### Node ##################################### # Node names are generated dynamically on startup, so you&#39;re relieved # from configuring them manually. You can tie this node to a specific name: # node.name: &amp;quot;GRAYLOG2&amp;quot; [/code] --OMITTED-- [code highlight=&amp;quot;7&amp;quot;] # Unicast discovery allows to explicitly control which nodes will be used # to discover the cluster. It can be used when multicast is not present, # or to restrict the cluster communication-wise. # # 1. Disable multicast discovery (enabled by default): # discovery.zen.ping.multicast.enabled: false # # 2. Configure an initial list of master nodes in the cluster # to perform discovery when new nodes (master or data) are started: # #discovery.zen.ping.unicast.hosts: [&amp;quot;host1&amp;quot;, &amp;quot;host2:port&amp;quot;] # EC2 discovery allows to use AWS EC2 API in order to perform discovery. # # You have to install the cloud-aws plugin for enabling the EC2 discovery.[/code] Restart Elasticsearch service: [code]systemctl restart elasticsearch[/code] Verify service is running: [code]systemctl status elasticsearch[/code] Open your browser up to &lt;a href=&#34;http://ip-address:9200/_plugin/head/&#34;&gt;http://ip-address:9200/_plugin/head/&lt;/a&gt; you should now see your elasticsearch node named correctly. [caption id=&amp;quot;attachment_3633&amp;quot; align=&amp;quot;aligncenter&amp;quot; width=&amp;quot;572&amp;quot;]&lt;img src=&#34;https://systemstechblog.files.wordpress.com/2015/12/graylog2-1.png&#34; alt=&#34;graylog2-1&#34;&gt; Elasticseach Node up and running on server Graylog2[/caption] On server &lt;strong&gt;Graylog1:&lt;/strong&gt; Allow the installation of EPEL packages, We use this to install pwgen if you have another way of generating random passwords then you don&#39;t need it. To install EPEL packages on Centos 7: [code]rpm -Uvh &lt;a href=&#34;https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm&#34;&gt;https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm&lt;/a&gt;[/code] Install pwgen: [code]yum install pwgen[/code] Install the Mango software repositories Reference: &lt;a href=&#34;http://docs.mongodb.org/manual/tutorial/install-mongodb-on-red-hat/&#34;&gt;http://docs.mongodb.org/manual/tutorial/install-mongodb-on-red-hat/&lt;/a&gt; Create a /etc/yum.repos.d/mongodb-org-3.2.repo file so that you can install MongoDB directly, using yum. [code]nano /etc/yum.repos.d/mongodb-org-3.2.repo[/code] Copy following into the mongodb-org3.2.repo [code] [mongodb-org-3.2] name=MongoDB Repository baseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.2/x86_64/ gpgcheck=0 enabled=1[/code] Install Mongodb: [code]yum install mongodb-org[/code] Once installed start it up by running this command: [code]/etc/init.d/mongod start[/code] Verify mongo is up and running by running the mongo command. Should look something like this: [code][root@GRAYLOG1 ~]# mongo MongoDB shell version: 3.2.0 connecting to: test Server has startup warnings: 2015-12-22T18:30:06.804-0700 I CONTROL [initandlisten] 2015-12-22T18:30:06.804-0700 I CONTROL [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/enabled is &#39;always&#39;. 2015-12-22T18:30:06.804-0700 I CONTROL [initandlisten] ** We suggest setting it to &#39;never&#39; 2015-12-22T18:30:06.804-0700 I CONTROL [initandlisten] 2015-12-22T18:30:06.804-0700 I CONTROL [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/defrag is &#39;always&#39;. 2015-12-22T18:30:06.804-0700 I CONTROL [initandlisten] ** We suggest setting it to &#39;never&#39; 2015-12-22T18:30:06.804-0700 I CONTROL [initandlisten] 2015-12-22T18:30:06.804-0700 I CONTROL [initandlisten] ** WARNING: soft rlimits too low. rlimits set to 4096 processes, 64000 files. Number of processes should be at least 32000 : 0.5 times number of files. 2015-12-22T18:30:06.804-0700 I CONTROL [initandlisten][/code] Make sure Mongo starts up when the server reboots: [code]chkconfig -- mongodb[/code] We are now ready to install Graylog sever and Graylog Web Reference: &lt;a href=&#34;http://docs.graylog.org/en/1.3/pages/installation/operating_system_packages.html&#34;&gt;http://docs.graylog.org/en/1.3/pages/installation/operating_system_packages.html&lt;/a&gt; Run the following commands, RPM is to get the package version so we can install it using yum. [code]sudo rpm -Uvh &lt;a href=&#34;https://packages.graylog2.org/repo/packages/graylog-1.3-repository-el7&#34;&gt;https://packages.graylog2.org/repo/packages/graylog-1.3-repository-el7&lt;/a&gt;_latest.rpm sudo yum install graylog-server graylog-web[/code] When/If the server reboots let’s make sure graylog starts up with it: [code]systemctl enable graylog-server systemctl enable graylog-web[/code] Now we need to edit the graylog configuration: [code]nano /etc/graylog/server/server.conf[/code] Make the following edits: &lt;em&gt;&lt;strong&gt;Note:&lt;/strong&gt; For the shasum -a 256 command, use sha256sum instead.&lt;/em&gt; _ Example: echo -n yourpassword | shasum -a 256 BECOMES echo -n yourpassword | sha256sum_ [code highlight=&amp;quot;3,11,22&amp;quot;]# If you are running more than one instances of graylog2-server you have to select one of these # instances as master. The master will perform some periodical tasks that non-masters won&#39;t perform. is_master = true # The auto-generated node ID will be stored in this file and read after restarts. It is a good idea # to use an absolute file path here if you are starting graylog2-server from init scripts or similar. node_id_file = /etc/graylog/server/node-id # You MUST set a secret to secure/pepper the stored user passwords here. Use at least 64 characters. # Generate one by using for example: pwgen -N 1 -s 96 password_secret = YOUR_SECRET_PASSWORD_GOES_HERE # The default root user is named &#39;admin&#39; #root_username = admin # You MUST specify a hash password for the root user (which you only need to initially set up the # system and in case you lose connectivity to your authentication backend) # This password cannot be changed using the API or via the web interface. If you need to change it, # modify it in this file. # Create one by using for example: echo -n yourpassword | shasum -a 256 # and put the resulting hash value into the following line root_password_sha2 =YOUR_PASSWORD_HASH_GOES_HERE # The email address of the root user. # Default is empty #root_email = &amp;quot;&amp;quot; # The time zone setting of the root user. # The configured time zone must be parseable by &lt;a href=&#34;http://www.joda.org/joda-time/apidocs/org/joda/time/DateTimeZone.html#forID-java.lang.String-&#34;&gt;http://www.joda.org/joda-time/apidocs/org/joda/time/DateTimeZone.html#forID-java.lang.String-&lt;/a&gt; # Default is UTC #root_timezone = UTC [/code] --OMITTED-- [code highlight=&amp;quot;6,18,23,26,38,39&amp;quot;]# How many Elasticsearch shards and replicas should be used per index? Note that this only applies to newly created indices. elasticsearch_shards = 4 elasticsearch_replicas = 0 # Prefix for all Elasticsearch indices and index aliases managed by Graylog. elasticsearch_index_prefix = graylog # Name of the Elasticsearch index template used by Graylog to apply the mandatory index mapping. # # Default: graylog-internal #elasticsearch_template_name = graylog-internal # Do you want to allow searches with leading wildcards? This can be extremely resource hungry and should only # be enabled with care. See also: &lt;a href=&#34;https://www.graylog.org/documentation/general/queries/&#34;&gt;https://www.graylog.org/documentation/general/queries/&lt;/a&gt; allow_leading_wildcard_searches = false # Do you want to allow searches to be highlighted? Depending on the size of your messages this can be memory hungry and # should only be enabled after making sure your Elasticsearch cluster has enough memory. allow_highlighting = true # settings to be passed to elasticsearch&#39;s client (overriding those in the provided elasticsearch_config_file) # all these # this must be the same as for your Elasticsearch cluster elasticsearch_cluster_name = graylog # you could also leave this out, but makes it easier to identify the graylog2 client instance elasticsearch_node_name = graylog1 # we don&#39;t want the graylog2 server to store any data, or be master node #elasticsearch_node_master = false #elasticsearch_node_data = false # use a different port if you run multiple Elasticsearch nodes on one machine #elasticsearch_transport_tcp_port = 9350 # we don&#39;t need to run the embedded HTTP server here #elasticsearch_http_enabled = false elasticsearch_discovery_zen_ping_multicast_enabled = false elasticsearch_discovery_zen_ping_unicast_hosts = 192.168.148.132:9300 # Change the following setting if you are running into problems with timeouts during Elasticsearch cluster discovery. # The setting is specified in milliseconds, the default is 5000ms (5 seconds). #elasticsearch_cluster_discovery_timeout = 5000 [/code] Add the following firewall rule: [code]firewall-cmd --permanent --zone=public --add-port=9000/tcp firewall-cmd --permanent --zone=public --add-port=9201-9400/tcp firewall-cmd --reload[/code] Configure the Graylog web server configuration file located at /etc/graylog/web/web.conf. [code highlight=&amp;quot;2,12&amp;quot;]# graylog2-server REST URIs (one or more, comma separated) For example: &amp;quot;http://127.0.0.1:12900/,http://127.0.0.1:12$ graylog2-server.uris=&amp;quot;http://127.0.0.1:12900&amp;quot; # Learn how to configure custom logging in the documentation: # &lt;a href=&#34;http://docs.graylog.org/en/latest/pages/installation.html#manual-setup-graylog-web-interface-on-linux&#34;&gt;http://docs.graylog.org/en/latest/pages/installation.html#manual-setup-graylog-web-interface-on-linux&lt;/a&gt; # Secret key # ~~~~~ # The secret key is used to secure cryptographics functions. Set this to a long and randomly generated string. # If you deploy your application to several instances be sure to use the same key! # Generate for example with: pwgen -N 1 -s 96 application.secret=&amp;quot;YOUR_SECRET_PASSWORD_GOES_HERE&amp;quot; # Web interface timezone # Graylog stores all timestamps in UTC. To properly display times, set the default timezone of the interface. # If you leave this out, Graylog will pick your system default as the timezone. Usually you will want to configure it. # timezone=&amp;quot;Europe/Berlin&amp;quot; # Message field limit # Your web interface can cause high load in your browser when you have a lot of different message fields. The default # limit of message fields is 100. Set it to 0 if you always want to get all fields. They are for example used in the # search result sidebar or for autocompletion of field names. field_list_limit=100 # Use this to run Graylog with a path prefix #application.context=/graylog2 # You usually do not want to change this. application.global=lib.Global # Global timeout for communication with Graylog server nodes; default: 5s #timeout.DEFAULT=5s # Accept any server certificate without checking for validity; required if using self-signed certificates. # Default: true # graylog2.client.accept-any-certificate=true[/code] Start them up! Both graylog-server and graylog-web. [code]systemctl start graylog-server systemctl start graylog-web[/code] Verify both are running: [code][root@GRAYLOG1 ~]# systemctl status graylog-server â graylog-server.service - Graylog server Loaded: loaded (/usr/lib/systemd/system/graylog-server.service; enabled; vendor preset: disabled) Active: active (running) since Wed 2015-12-23 20:05:38 MST; 11s ago Docs: &lt;a href=&#34;http://docs.graylog.org/&#34;&gt;http://docs.graylog.org/&lt;/a&gt; Main PID: 11758 (graylog-server) CGroup: /system.slice/graylog-server.service ââ11758 /bin/sh /usr/share/graylog-server/bin/graylog-server ââ11759 /usr/bin/java -Xms1g -Xmx1g -XX:NewRatio=1 -XX:PermSize=128m -XX:MaxPermSize=256m -se... Dec 23 20:05:38 GRAYLOG1 systemd[1]: Started Graylog server. Dec 23 20:05:38 GRAYLOG1 systemd[1]: Starting Graylog server... Dec 23 20:05:38 GRAYLOG1 graylog-server[11758]: OpenJDK 64-Bit Server VM warning: ignoring option Per...8.0 Dec 23 20:05:38 GRAYLOG1 graylog-server[11758]: OpenJDK 64-Bit Server VM warning: ignoring option Max...8.0 Hint: Some lines were ellipsized, use -l to show in full. [root@GRAYLOG1 ~]# systemctl status graylog-web â graylog-web.service - Graylog web interface Loaded: loaded (/usr/lib/systemd/system/graylog-web.service; enabled; vendor preset: disabled) Active: active (running) since Wed 2015-12-23 20:05:43 MST; 13s ago Docs: &lt;a href=&#34;http://docs.graylog.org/&#34;&gt;http://docs.graylog.org/&lt;/a&gt; Main PID: 11777 (graylog-web) CGroup: /system.slice/graylog-web.service ââ11777 /bin/sh /usr/share/graylog-web/bin/graylog-web ââ11778 java -Xms1024m -Xmx1024m -XX:ReservedCodeCacheSize=128m -Dconfig.file=/etc/graylog/we... Dec 23 20:05:43 GRAYLOG1 systemd[1]: Started Graylog web interface. Dec 23 20:05:43 GRAYLOG1 systemd[1]: Starting Graylog web interface... [root@GRAYLOG1 ~]#[/code] You should be able get to the Graylog Web interface by going to &lt;a href=&#34;http://ip-address:9000/&#34;&gt;http://ip-address:9000/&lt;/a&gt;. You should see a login screen, type in admin followed by your password that you created. [caption id=&amp;quot;attachment_3688&amp;quot; align=&amp;quot;aligncenter&amp;quot; width=&amp;quot;1375&amp;quot;]&lt;img src=&#34;https://systemstechblog.files.wordpress.com/2016/01/graylog1-2.png&#34; alt=&#34;graylog1-2&#34;&gt; Graylog Login Screen[/caption] Once logged if you get an error about an exception and an &amp;quot;OOps Message&amp;quot; You are likely typing the IP address of the of the server. There is some type of Java error that makes Graylog not happy :( so to fix it you can do two things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use the DNS name of the server if you have local DNS servers, Graylog has to use these DNS servers as well.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;or&#34;&gt;OR&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Edit the local server&#39;s host file and put in the hostname of the server and the IP address of it to fix this error.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Go to /etc/hosts using nano: (In this example the 192.168.148.130 is the Graylog1 server&#39;s IP address and the hostname of this Graylog server is GRAYLOG1) [code]127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 192.168.148.130 GRAYLOG1[/code] After you edit that hosts file just refresh your browser session. You now have installed GRAYLOG! :). [caption id=&amp;quot;attachment_3639&amp;quot; align=&amp;quot;aligncenter&amp;quot; width=&amp;quot;1358&amp;quot;]&lt;img src=&#34;https://systemstechblog.files.wordpress.com/2015/12/graylog1-1.png&#34; alt=&#34;graylog1-1&#34;&gt; Graylog Web Interface[/caption] It&#39;s a little bit of an effort to get this thing up and running but you now have a logging system that is ready to go. If you want this thing in production please look at the documentation that Graylog offers as there are things that I did not even mention, this was bare bones installation and Graylog has a lot to offer. I hope this information was helpful, now let&#39;s kick-off 2016! Links: &lt;a href=&#34;https://www.graylog.org/&#34;&gt;https://www.graylog.org/&lt;/a&gt; &lt;a href=&#34;http://docs.graylog.org/en/1.3/&#34;&gt;http://docs.graylog.org/en/1.3/&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
  </channel>
</rss>
